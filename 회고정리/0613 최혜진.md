# IAM 이란?
Identity and Access Management
누가, 어떤 리소스나 서비스를 사용할 수 있는지 접근 레벨이나 권한 관리 기능을 제공한다.
대부분 AWS 리소스는 지역에 따라 제공되는 서비스와 기능이 다르지만 IAM 은 UNIVERSAL 하다.
따라서 IAM 사용 시 따로 지역을 설정해줄 필요가 없는 것이다.

'루트 유저' 는 모든 리소스를 제약 없이 사용할 수 있을 뿐만 아니라 새로운 유저도 만들 수 있다.
'루트 유저' 는 새롭게 만들어진 유저의 권한을 직접 조작할 수도 있다.

IAM 은 리소스에 대한 권한만 관리하는 것이 아닌 리소스 안에서 이루어지는 다양한 행동에 대한 세밀한 접근 권한 관리도 할 수 있다.

## IAM 으로 무엇을 할 수 있나?
#### IAM 의 목적
특정 리소스에만 접근할 수 있고, 특정 데이터만 불러오고 수정할 수 있게 제약을 둠으로써 **최소 권한 정책**을 적용하는 것이다.

![[Pasted image 20240612213727.png|400]]

> A회사 : 날씨와 관련된 데이터(온도, 강우량, 습도 등) 를 실시간으로 불러와 다양한 데이터 분석을 진행하며, 분석한 데이터의 인사이트를 외부에 알리는 회사
> 가 있다고 한다면, 
> 1. 외부에서 데이터를 전달받고 회사 내에서 데이터를 전처리하는 파이프라인을 구축하는 데이터 엔지니어팀
> 2. 전처리가 완료된 데이터를 데이터베이스에 보관하는 파이프라인을 구축하는 소프트웨어 엔지니어팀
> 3. 데이터를 근거로 대시보드를 만들고 관리하며 리포트를 생성하는 데이터 분석팀
> 
> 이렇게 각 팀은 각자만의 고유한 업무가 존재하며 업무 처리를 위해 접근해야 하는 소스와 파이프라인을 거쳐 최종적으로 생산되는 결과물이 다르다. 

각자 업무에 해당하는 권한만 가지고 있어도 업무 수행에 있어 지장이 없을 것이다. 
이렇게 각 팀마다 필요로 하는 AWS  리소스는 천차만별이고 이에 따라 요구되는 권한도 다르다.
이럴 때 사용하는 용어가 바로   **'최소 권한 정책'**   이다.

만약 모든 팀에게 루트 유저 역할을 부여한다면?
다른 팀 사람이 엉뚱한 것을 잘못 건드려서 프로덕션에 차질이 생기면 회사 내에 피해가 클 것.

그래서 최소 권한 정책은 팀에서 그들의 업무를 진행하는데 최소한의 역할만 제공하고 (필요한 AWS 리소스에 대한 권한만 부여) 그 이외에 대한 접근은 차단시킨다는 것이다.
이는 보안 측면에서도 중요한 개념이다.

## IAM 에서 생성하고 관리하는 것
##### 1. 유저(User)
액세스 키와 비밀 키를 가지고 AWS 리소스를 사용하는 객체이다.
##### 2. 그룹(Group)
하나 혹은 여러 유저를 담고 있다.
접근 권한을 설정할 때 유저 개개인이 아닌 그룹에 적용시킬 수 있다.
그러면 그룹 안에 속해있는 모든 유저가 영향을 받게 된다.
일반적으로 유저보다는 그룹에 특정 권한을 제공한다. 

>그렇다면 앞서 설명했던 A 회사 예시에서는 
어떻게 그룹으로 만들 수 있을까?
→ 그룹1 : 데이터 엔지니어팀,  그룹2: 소프트웨어 엔지니어팀,  그룹3: 데이터 분석팀

##### 3. 역할(Role)
역할은 하나 혹은 다수의 정책을 포함할 수 있다.
대부분의 역할은 AWS 에서 디폴트로 제공하지만, 다양한 정책을 합쳐서 새로운 역할을 만들어 유저 및 그룹에 적용시킬 수 있다.
##### 4. 정책(Policy)
정책을 만들어서 최소 권한 정책을 펼칠 수 있다.

정책 A 는 데이터베이스 읽기 전용
정책 B는 대시보드 생성 후 모든 작업을 진행할 수 있는 admin 모드
정책 C는 루트 유저 권한으로 설정
즉, 다양한 정책을 만들어서 유저 및 그룹에 적용시킬 수 있다.

## IAM 실습

1. **유저 만들기(사용자 만들기)**
	루트 유저 권한으로 새로운 유저를 만들어 본다.
	이때 사용자의 엑세스 키가 유출되지 않도록 조심해야 한다.
	MFA (다요소 인증 - Multi-factor authentication)를  활성화 해주면 2차 인증을 거치면서 보안이 강화된다.
2. 사용자 그룹 만들기 (유저 관리)
	여러 유저를 관리하는 사용자 그룹을 만들어 본다.
	사용자를 추가하고 정책을 추가해본다.
	모든 유저는 추가하는 정책의 영향을 받는다.
	이때 직접 정책을 생성할 수도 있다.
3. 역할 만들기
	역할은 사용자에게 다양한 정책을 제공할 수 있는 기능을 부여한다.
	IAM 에 들어가서 역할 만들기를 통해 역할을 만들어본다.
	주로 교차 계정 접근, 서비스 간 권한 위임, EC2 인스턴스에 대한 권한 부여 등에 사용된다.
4. 정책 만들기
	권한을 정의하는 JSON 문서이다.
	정책 만들기를 해본다. 
	정책에는 사용자, 그룹, 역할이 특정 AWS 리소스에 대해 수행할 수 있는 작업을 정의한다.
	정책은 크게 관리형 정책( 미리 만들어진 정책 ) 과 사용자 정의 정책 (직접 작성하는 정책 ) 으로 나눌 수 있다.
	정책을 통해서 세밀하게 접근 권한을 제어할 수 있다.

어제 역할 실습에서 해본 것 중에 EC2 인스턴스에 가서 
![[Pasted image 20240612165354.png]]
역할을 따로 만들어서 그 역할을 EC2 인스턴스에 할당하는 걸 해봤다.

**여기서 이해해야 될 부분 :** 
만약 EC2 인스턴스에 `S3ReadOnlyAccess` 역할을 할당했다면, 이 인스턴스는 S3 버킷에서 데이터를 읽을 수 있는 권한을 갖게 된다. 이는 IAM 사용자에게 `S3ReadOnlyAccess` 정책을 직접 부여하는 것과 같은 효과를 가지며, EC2 인스턴스가 해당 권한을 대신 수행할 수 있게 되는 것이다.


# EC2
Elastic Compute Cloud
AWS 에서 자주 사용되는 서비스로 클라우드 공간에 크기가 유연하게 변경되는 가상 서버 기능을 제공한다.
EC2는 인스턴스라고도 불리며 클라우드 공간에 가상 서버(virtual server) 를 만들어 AWS 에서 제공하는 다양한 애플리케이션을 돌릴 수 있다.

> 프로젝트에서 할당될 용량을 미리 예측하는 것은 불가능하다.
> 사용량이 많으면 디스크 크기를 늘리고, 사용량이 적을 때 디스크 크기를 줄일 수 있다면 얼마나 좋을까?
> 바로 이럴 때 EC2를 사용하는 것이다!

# RDS
Relational Database Service
클라우드 환경에서 관계형 데이터베이스를 쉽게 설정, 운영 및 확장할 수 있게 해주는 완전 관리형 서비스이다.
### 주요 특징
###### 1. **완전 관리형 서비스**
	데이터베이스의 프로비저닝, 패치 관리,백업, 복구 등 일상적인 데이터베이스 작업 관리를 자동화한다.
	이를 통해 관리에 소요되는 시간을 절약하고, 핵심 비지니스에 집중할 수 있다.
###### 2. **다양한 데이터베이스 엔진 지원**
   MySQL, PostgreSQL, MariaDB, Oracle, Microsoft SQL Server, Amazon Aurora 등 다양한 데이터베이스 엔진을 지원한다. 
###### 3. **확장성 및  고가용성**
   읽기 성능 향상을 위한 읽기 복제본 기능과 장애 조치 기능을 제공해 고가용성을 보장한다.
###### 4. **보안**
   데이터베이스 인스턴스에 대한 네트워크 접근 제어, 데이터 암호화, 보안 그룹 설정 등을 통해 높은 수준의 보안을 제공한다.
###### 5. **자동 백업 및 복구**
   자동 백업 기능을 제공하여 사용자가 설정한 보존 기간동안 데이터베이스의 정기적 스냅샷을 생성한다.
   이를 통해 데이터 손실 시에도 손쉽게 특정 시점으로 복구 가능하다.
   
   
   RDS 에서 데이터베이스를 만들 때 디폴트로 활성화되는 자동 백업(AB)은 1~35일의 보유 기간내에 특정 시간으로 데이터베이스 상태를 복원할 수 있다.
   복원이 가능하게 하기 위해서 스냅샷과 트랜잭션 로그를 생성한다.
   
   이때 데이터베이스에서의 스냅샷이란 데이터베이스 인스턴스를 통째로 복사한다고 이해하면 된다. 인스턴스에는 스토리지 볼륨 정보, 파일의 크기, 스냅샷이 만들어진 시간 등 다양한 정보를 담고 있다.  스냅샷은 앞서 살펴본 자동 백업과는 달리 개발자가 수도으로 실행시켜야 한다.
   즉,  스냅샷은 RDS 인스턴스 생성 시 바로 만들어지는게 아니다. 
   
   왜 스냅샷을 쓰냐? 한다면, 원본 RDS 인스턴스를 삭제해도 스냅샷은 여전히 존재하기 때문에 기존 인스턴스를 살릴 수 있는 큰 장점이 있어서 쓴다.
   
| **특성**               | **자동 백업 스냅샷**                                       | **수동 백업 스냅샷**         |
| -------------------- | --------------------------------------------------- | --------------------- |
| **생성 방법**            | 자동으로 생성                                             | 사용자가 직접 생성            |
| **보관 기간**            | 설정된 보관 기간에 따라 자동 삭제                                 | 사용자가 삭제할 때까지 유지       |
| **RDS 인스턴스 삭제 시 처리** | <span style="background:#ffbb99">인스턴스와 함께 삭제</span> | <span style="background:#ffbb99">인스턴스 삭제 후에도 유지</span>        |
| **목적**               | 주기적인 백업 및 복구 용도                                     | 특정 시점의 데이터 보존 및 복구 용도 |
| **관리 편의성**           | 자동으로 관리                                             | 수동으로 관리 필요            |
| **비용**               | 기본적으로 포함된 비용                                        | 추가 비용 발생 가능           |


# S3
Simple Storage Service
AWS 의 메인 스토리지이며 매우 안전하고 가변적인 오브젝트 저장 공간을 제공한다.
가변적이라는 특징 때문에 스토리지 공간에 구애받지 않고 마음껏 사용할 수 있으며 AWS 자체에서 보안을 신경 쓰기 때문에 사용자는 마음 편히 **오브젝트를 업로드/ 다운로드** 할 수 있다.

S3 버킷 공간은 무제한이라 스토리지 공간 부족을 걱정할 필요가 전혀 없다.

버킷은 S3에서 중요한 개념이다.

#### 버킷이란?
데이터를 저장하기 위한 컨테이너이다.
데이터 저장 및 관리의 기본 단위 역할을 하며 파일(객체)를 저장할 수 있는 공간을 제공하고, 각 버킷은 전역적으로 고유한 이름을 가져야 한다.

# AWS SSM
aws systems manager
AWS 클라우드 환경 및 온프레미스 환경에서 시스템 관리를 자동화하고 제어하며 효율적으로 운영할 수 있도록 도와주는 서비스이다.

우리가 수업 중 다룬 내용인 parameter store에 대해 알아보자.

### Parameter Store 이란?
애플리케이션 설정 데이터 및 비밀 정보를 안전하게 저장하고 관리할 수 있는 완전 관리형 서비스이다.
parameter store를 사용하면 중요한 구성 데이터와 암호를 키 - 값 쌍 형태의 텍스트 문자열로 데이터를 저장하며, 암호화된 데이터를 지원한다.

데이터베이스 연결 정보, API 키, 비밀번호 등의 정보를 안전하게 저장하고 관리할 수 있다. → 보안 강화, 편의성 ↑

#### parameter store 사용법
###### 1. 매개 변수 생성
   ```bash
   aws ssm put-parameter --name "MyParameter" --value "MyValue" --type String
```
![[Pasted image 20240612133652.png]]
직접 AWS Systems Manager > parameter store > parameter 생성을 통해 할 수도 있다.
###### 2. 매개 변수 조회
   ```bash
   aws ssm get-parameter --name "MyParameter"
```

###### 3. 매개 변수 업데이트
   ```bash
   aws ssm put --parameter --name "MyParameter" --value "NewValue" --overwrite
```

###### 4. 매개 변수 삭제
```bash
   aws ssm delete-parameter --name "MyParameter"
```

## 실습
##### 1. 의존성 추가 build.gradle
```gradle
implementation platform("io.awspring.cloud:spring-cloud-aws-dependencies:3.1.1")  
implementation 'io.awspring.cloud:spring-cloud-aws-starter-parameter-store:3.1.1'
implementation 'io.awspring.cloud:spring-cloud-aws-starter-s3:3.1.1'
```

1. io.awspring.cloud:spring-cloud-aws-dependencies
   Spring cloud Aws 의존성 관리
2. io.awspring.cloud:spring-cloud-aws-starter-parameter-store
   Aws Parameter Store 를 사용하기 위한 의존성
3. io.awspring.cloud:spring-cloud-aws-starter-s3
   Aws S3 서비스를 사용할 수 있도록 도와주는 의존성
   
##### 2. application.yml 코드 추가
```yml
cloud:  
  aws:  
    region:  
      static: ap-northeast-2 # Seoul region 설정 해주기  
config:  
  import:  
    - aws-parameterstore:/todo/config/
```
aws 리전 설정을 정의하는 코드와 Spring Boot가 애플리케이션 설정을 추가로 가져올 위치를 지정한다.
aws-parameterstore:/todo/config/ 경로에서 추가 설정을 가져온다.
이 설정은 AWS Systems Manager Parameter Store 에서 /config/ 경로 아래에 있는 매개변수를 읽어온다.

이외의 Service , Controller, Repository, Entity 코드는 너무 길어지니 따로 첨부는 생략하겠다.

##### 3. 애플리케이션 실행
 1. AWS 자격 증명 로드
   .aws/credentials 및 .aws/config 파일에서 AWS 자격 증명과 리전 정보를 읽어온다.
   ![[스크린샷 2024-06-12 104949.png]]
2. SSM Parameter Store 접근 
   Spring Cloud AWS 가 SsmClient 빈을 생성하고, 설정된 리전과 자격 증명을 사용해 Parameter Store에 접근한다.
   
 3. 설정 값 로드
    ![[Pasted image 20240612213305.png]]
    spring.config.import 설정에 따라 /config/ 경로 아래에 있는 매개 변수를 읽어온다.
    
4. 설정 값 주입
   읽어온 매개 변수를 애플리케이션 컨텍스트에 주입하여 spring.datasource.username과 spring.datasource.password 값을 설정한다.
   
5. 데이터베이스 연결
   주입된 값을 사용해 데이터베이스에 연결한다.


## 코드 이해
### 1. TodoApplication
```java
@Bean
public CommandLineRunner run() {
    return args -> {
        String region = "ap-northeast-2";

        SsmClient ssmClient = SsmClient.builder()
                .region(Region.of(region))
                .build();

        System.out.println("todo_DB_USERNAME:::" + getPamameterValue(ssmClient, "/todo/config/DB_USERNAME"));
        System.out.println("todo_DB_PASSWORD:::" + getPamameterValue(ssmClient, "/todo/config/DB_PASSWORD"));
    };
}

```

1. region 변수를 설정해 aws 리전을 지정한다.
2. SsnClient 인스턴스를 생성한다. 이 클라이언트는 AWS SSM 서비스를 호출하는데 사용한다.
3. 아래의 getparametervalue 메서드를 사용해 SSM Parameter Store 에서 값을 가져와 출력한다.
   ![[Pasted image 20240612214644.png]]
   GetParameterRequest 객체를 생성해서 파라미터 이름과 'withDecryption' 옵션을 설정한다.
   withDecryption(true)를 설정해 암호화된 값이 있는 경우 복호화해 가져온다. 
   ssnClient.getParameter 메서드를 호출해 파라미터 값을 가져온다.
   GetParameterResponse 객체에서 파라미터 값을 추출해 반환한다.
   ![[스크린샷 2024-06-12 142326.png]]
   실행시키면 이런 식으로 뜨게 된다.

### 2. 마지막 실습,,,코드 이해하기
Spring Boot 애플리케이션에서 Amazon S3 를 사용해 파일을 업로드하고 다운로드하며, 업로드된 파일의 메타데이터를 데이터베이스에 저장하고 검색하는 실습을 하였다. 
##### 1. Service 클래스 (파일 S3에 업로드, 다운로드드)

```java
@Service
@RequiredArgsConstructor
public class S3Service {
    private final S3Client s3Client;
    private final String bucketName = "ddaru-s3-bucket";

    public void uploadFile(MultipartFile multipartFile, String key) throws IOException {
        s3Client.putObject(
                PutObjectRequest.builder()
                        .bucket(bucketName)
                        .key(key)
                        .build(),
                RequestBody.fromBytes(multipartFile.getBytes())
        );
    }

    public InputStream downloadFile(String key) {
        return s3Client.getObject(
                GetObjectRequest.builder()
                        .bucket(bucketName)
                        .key(key)
                        .build()
        );
    }
}
```

**==uploadFile 메서드==**

매개변수로 MultipartFile, key를 받는다.
MultipartFile multipartfile 은 업로드할 파일을 나타내는 spring 의  multipartfile객체다.
String key는 S3 버킷 내에서 파일을 식별하기 위한 고유한 키(경로) 이다.

PutObjectRequest.builder() 을 통해 PutObjectRequest 객체의 빌더를 생성하고, 
업로드할 S3 버킷의 이름을 지정해주고, 버킷 내에서 파일을 저장할 경로 및 파일 이름을 지정한다.
마지막으로 설정된 매개변수로 PutObjectRequest 객체를 빌드한다.

RequestBody.fromBytes(multipartFile.getBytes()) 를 통해 Multipartfile 객체에서 파일의 바이트 배열을 추출해서 RequestBody로 변환한다.

이걸!!!! s3Client.putObject(...) 를 통해 S3 클라이언트를 사용해 S3 버킷에 파일을 업로드한다.
이때 첫 번째 매개변수로 PutObjectRequest를 전달하고 두 번째 매개변수로 파일의 내용을 포함하는 RequestBody를 전달한다.

> 결론적으로, uploadFile 메서드는 MultipartFile 객체로부터 파일의 데이터를 가져와 지정된 S3 버킷의 경로에 업로드한다.
> 파일은 S3 버킷 내에서 지정된 키를 사용해 저장한다.

**==downloadFile 메서드==**

매개변수로 key 를 받는다.
다운로드할 파일을 식별하기 위해 S3 버킷 내의 고유한 키를 받는다.

GetObjectRequest.builder() 를 통해 GetObjectRequest 객체의 빌더를 생성하고, 다운로드할 파일이 저장된 S3 버킷의 이름을 지정하고, 다운로드할 파일의 경로 및 이름을 지정한다.
마지막으로 설정된 매개변수로 GetObjectRequest 객체를 빌드한다.

이걸 또,,,!!! s3Client.getObject(...) 를 통해 S3 클라이언트를 사용해 S3 버킷에서 파일을 다운로드 한다. 
이때 매개변수로 GetObjectRequest 를 전달한다.
반환 값은 InputStream 으로 파일의 내용을 스트림 형태로 읽을 수 있다.

>결론적으로, downloadFile 메서드는 지정된 키를 사용해 S3 버킷에서 파일을 다운로드하고, 해당 파일의 내용을 읽을 수 있는 InputStream 을 반환한다.
>이때의 InputStream 은 파일의 내용을 바이트 단위로 읽는데 사용된다.

##### 2. Service (파일의 메타데이터를 데이터베이스에 저장하고 조회하는 기능)
```java
@Service  
@RequiredArgsConstructor  
public class FileDatabaseService {  
    private final FileRepository fileRepository;  
    @Transactional  
    public FileEntity saveFileMetadata(String uuid, String path, String originalFilename, Long size, String mimeType) {  
        FileEntity fileEntity = new FileEntity();  
        fileEntity.setUuid(uuid);  
        fileEntity.setPath(path);  
        fileEntity.setOriginalFilename(originalFilename);  
        fileEntity.setSize(size);  
        fileEntity.setMimeType(mimeType);  
        return fileRepository.save(fileEntity);  
    }  
    public Optional<FileEntity> getFileMetadata(String uuid) {  
        return fileRepository.findByUuid(uuid);  
    }  
}
```


FileRepository  인터페이스는 파일 엔티티에 대한 데이터베이스 작업을 수행하기 위한 메서드를 제공한다.
###### Repository 클래스
```java
public interface FileRepository extends JpaRepository<FileEntity, Long> {  
    Optional<FileEntity> findByUuid(String uuid);  
}
```
- JpaRepository<FileEntity, Long> 를 상속받아 기본적인 CRUD 메서드 사용
- findByUuid 메서드는 파일의 고유 Uuid로 검색한다.

saveFileMetadata 메서드는 파일의 메타데이터(파일에 관련된 정보)를 저장하기 위한 메서드이다.
파일의 UUID(고유 식별자), 경로, 원본 파일 이름, 크기, MIME 타입을 인자로 받는다.
이러한 정보를 사용해 FileEntity 객체를 생성하고 이를 데이터베이스에 저장한 후에 저장된 엔티티를 반환한다.

getFileMetadata 메서드는 주어진 Uuid 에 해당하는 파일의 메타데이터를 조회하는 메서드이다.
이 메서드는 파일의 Uuid 를 인자로 받고, 해당 Uuid 에 해당하는 파일이 데이터베이스에 존재하면 이를 반환한다. 

> 결론적으로, 파일과 관련된 정보를 데이터베이스에 저장하고 조회하는 기능을 제공한다.

##### 3. Controller 클래스 (전체 코드)
```java
@RestController  
@RequiredArgsConstructor  
@RequestMapping("/s3")  
public class S3Controller {  
    private final S3Service s3Service;  
    private final FileDatabaseService fileDatabaseService;  
  
    @PostMapping("/upload")  
    public ResponseEntity<String> uploadFile(@RequestParam("file") MultipartFile file) {  
        try {  
            String uuid = UUID.randomUUID().toString();  
            String datePath = LocalDate.now().toString().replace("-", "/");  
            String key = datePath + "/" + uuid;  
  
            s3Service.uploadFile(file, key);  
            fileDatabaseService.saveFileMetadata(uuid, key, file.getOriginalFilename(), file.getSize(), file.getContentType());  
  
            return ResponseEntity.ok("File uploaded successfully: " + file.getOriginalFilename());  
        } catch (Exception e) {  
            return ResponseEntity.status(500).body("Failed to upload file: " + e.getMessage());  
        }  
    }  
    @GetMapping("/download/{uuid}")  
    public ResponseEntity<StreamingResponseBody> downloadFile(@PathVariable String uuid) {  
        try {  
            Optional<FileEntity> fileEntityOptional = fileDatabaseService.getFileMetadata(uuid);  
            if (!fileEntityOptional.isPresent()) {  
                return ResponseEntity.status(404).body(null);  
            }  
  
            FileEntity fileEntity = fileEntityOptional.get();  
            InputStream inputStream = s3Service.downloadFile(fileEntity.getPath());  
  
            StreamingResponseBody responseBody = outputStream -> {  
                byte[] buffer = new byte[1024];  
                int bytesRead;  
                while ((bytesRead = inputStream.read(buffer)) != -1) {  
                    outputStream.write(buffer, 0, bytesRead);  
                }  
                inputStream.close();  
            };  
  
            return ResponseEntity.ok()  
                    .contentType(MediaType.APPLICATION_OCTET_STREAM)  
                    .header(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + fileEntity.getOriginalFilename() + "\"")  
                    .body(responseBody);  
        } catch (Exception e) {  
            return ResponseEntity.status(500).body(null);  
        }  
    }
```
------
```java
private final S3Service s3Service;  
private final FileDatabaseService fileDatabaseService;

@PostMapping("/upload")  
public ResponseEntity<String> uploadFile(@RequestParam("file") MultipartFile file) {  
    try {  
        String uuid = UUID.randomUUID().toString();  
        String datePath = LocalDate.now().toString().replace("-", "/");  
        String key = datePath + "/" + uuid;  
  
        s3Service.uploadFile(file, key);  
        fileDatabaseService.saveFileMetadata(uuid, key, file.getOriginalFilename(), file.getSize(), file.getContentType());  
  
        return ResponseEntity.ok("File uploaded successfully: " + file.getOriginalFilename());  
    } catch (Exception e) {  
        return ResponseEntity.status(500).body("Failed to upload file: " + e.getMessage());  
    }  
}
```
@RequestMapping("/s3")  어노테이션을 사용해 '/s3' 경로를 기본 경로로 사용한다.

S3Service와 FileDatabaseService 인스턴스를 생성자 주입을 통해 의존성 주입을 받는다. → 서비스 객체를 사용해 Amazon S3와 데이터베이스와 상호작용한다.

@PostMapping("/upload) 어노테이션을 사용해 HTTP Post 요청을 처리하는 핸들러임을 나타내며 요청 경로는 /upload 이다.

uploadFile 메서드는 MultipartFile 타입의 file 이라는 요청 매개변수를 받아서 업로드 결과에 대한 응답을 나타낸다.
이때 업로드 작업은 예외가 발생될 수 있으니 try-catch 블록을 사용한다.

String uuid= UUID.randomUUID().toString() 에서는 UUID 클래스를 사용해 고유한 식별자를 생성한다. 이 UUID 는 업로드된 파일을 식별하는데 사용한다.

String datePath = LocalDate.now().toString().replace("-", "/") 는 현재 날짜를 사용해 경로를 생성하는 것이다 - 대신에 / 로 문자를 대체해 사용한 것을 알 수 있다.

String key = datePath + "/" + uuid 는 파일의 실제 저장 경로를 생성하는 것이다. 이것은 Amazon S3에 저장될 파일의 키이다.
우리가 실습을 통해 Amazon S3 에서 확인했을 때 2024/06/12 이런 식으로 생성된 것을 볼 수 있었다.

s3Service.uploadFile(file, key)에서는 s3Service 를 사용해 업로드된 파일을 Amazon S3 에 저장한다.

fileDatabaseService.saveFileMetadata(uuid, key, file.getOriginalFilename(), file.getSize(), file.getContentType()) 코드를 사용해 fileDatabaseService 를 사용해서 파일 관련 정보를 데이터베이스에 저장한다.

업로드가 성공되면 HTTP 상태 코드 200과 함께 업로드된 파일의 원본 이름을 포함한 메시지가 반환되며 파일 업로드 중 예외가 발생되면, HTTP 상태 코드 500과 함께 예외 메시지를 반환한다.

----
```java
@GetMapping("/download/{uuid}")  
public ResponseEntity<StreamingResponseBody> downloadFile(@PathVariable String uuid) {  
    try {  
        Optional<FileEntity> fileEntityOptional = fileDatabaseService.getFileMetadata(uuid);  
        if (!fileEntityOptional.isPresent()) {  
            return ResponseEntity.status(404).body(null);  
        }  
  
        FileEntity fileEntity = fileEntityOptional.get();  
        InputStream inputStream = s3Service.downloadFile(fileEntity.getPath());  
  
        StreamingResponseBody responseBody = outputStream -> {  
            byte[] buffer = new byte[1024];  
            int bytesRead;  
            while ((bytesRead = inputStream.read(buffer)) != -1) {  
                outputStream.write(buffer, 0, bytesRead);  
            }  
            inputStream.close();  
        };  
  
        return ResponseEntity.ok()  
                .contentType(MediaType.APPLICATION_OCTET_STREAM)  
                .header(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + fileEntity.getOriginalFilename() + "\"")  
                .body(responseBody);  
    } catch (Exception e) {  
        return ResponseEntity.status(500).body(null);  
    }  
}
```
@RequestMapping("/s3")  어노테이션을 사용해 '/s3' 경로를 기본 경로로 사용한다.

downloadFile 메서드에서는 경로 변수로부터 Uuid 를 받아온다. Uuid 는 다운로드할 파일을 식별하는데 사용된다.
다운로드 파일 메서드 또한 작업 중 예외를 발생시킬 수 있어서 try-catch 블록으로 예외 처리를 한다.

Optional<FileEntity>fileEntityOptional = fileDatabaseService.getFileMetadata(uuid);  는 파일의 Uuid 를 사용해 데이터베이스에서 파일에 관한 정보를 가져온다.

if (!fileEntityOptional.isPresent()) {  return ResponseEntity.status(404).body(null);}  만약 이 때 데이터베이스에서 파일을 찾지 못한 경우엔 상태 코드 404를 반환한다.

FileEntity fileEntity = fileEntityOptional.get();  코드를 통해 데이터베이스에서 찾은 파일에 관한 정보(메타데이터) 를 가져온다.

InputStream inputStream = s3Service.downloadFile(fileEntity.getPath());  는 s3Service 를 사용해서 Amazon S3에서 파일을 다운로드 하기 위해 파일의 경로를 사용한다. 다운로드된 파일의 내용을 읽기 위한 InputStream 을 가져온다.

StreamingResponseBody responseBody = outputStream -> { ... } 를 통해 파일 내용을 스트리밍 하기 위한 StreamingResponseBody 객체를 생성한다.
InputStream 에서 데이터를 읽어와서 클라이언트로 전송한다.

이때 다운로드가 성공하면 Http 상태코드 200과 함꼐 파일의 내용을 스트리밍 하는 응답을 반환한다. 
다운로드 중 예외가 발생되면 Http 상태코드 500과 함께 에러 응답을 반환한다.

> [!important] 내가 겪었던 상황,,
> AWS에서 VPC(Virtual Private Cloud)는 가상 네트워크 환경을 제공한다. 이를 통해 사용자는 AWS 리소스를 격리된 네트워크 환경에서 실행시킬 수 있는 것이다.
> 
> VPC 구성 요소
> **CIDR 블록 (Classless Inter-Domain Routing)**: VPC의 IP 주소 범위를 정의한다. 이는 VPC의 전체 IP 주소 범위를 나타낸다.
> 
> **서브넷(Subnet)**: VPC의 IP 주소 범위를 더 작은 네트워크로 분할한다. 서브넷은 특정 가용 영역에 속하며, 리소스를 배치할 때 사용된다.
> 
> **인터넷 게이트웨이(IGW)**: VPC와 인터넷 간의 통신을 가능하게 하는 게이트웨이이다.
> 
> **라우팅 테이블(Routing Table)**: 패킷의 전달 경로를 결정하는 데 사용된다. 서브넷은 라우팅 테이블에 연결되어야 인터넷 또는 다른 네트워크 리소스와 통신할 수 있다.
> 
> 서브넷을 제거하면 해당 서브넷 내의 리소스도 함께 제거된다. 이는 RDS와 같은 리소스가 해당 서브넷에 의존하는 경우에 문제가 될 수 있다. 이런 상황이 발생한 이유는 RDS 인스턴스를 생성하기 위해 선택한 서브넷이 제거되어 적절한 네트워크 환경이 없기 때문이다.
> 
> 서브넷을 함부로 제거하면 네트워크 구성에 심각한 영향을 줄 수 있다. 예를 들어, 다른 리소스와의 연결이 끊어질 수 있고, 인터넷으로의 액세스가 불가능해질 수 있다. 따라서 서브넷을 삭제하기 전에 관련된 모든 리소스를 확인하고, 해당 리소스를 다른 서브넷 또는 VPC로 마이그레이션해야 한다.
> 
> 요약하자면, 서브넷은 VPC 내에서 리소스를 배치하는 데 중요한 역할을 한다. 서브넷을 삭제하면 그 서브넷에 연결된 리소스도 함께 삭제되므로 신중하게 관리해야 한다.


> [!note] 참고
> [AWS 지식센터 | AWS re:Post (repost.aws)](https://repost.aws/ko/knowledge-center/deleted-default-vpc)
>  업무에서 바로 쓰는 AWS 입문, 김성민
>  강의 교안_클라우드 서비스와 아마존 웹서비스2




